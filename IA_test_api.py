from flask import Flask, request, jsonify
import openai
from openai import OpenAIError
from utils.vector_store import load_vector_store  # Assurez-vous que ce module est accessible
import logging
from flask_cors import CORS

# Configuration du logger
logging.basicConfig(level=logging.DEBUG, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # Autorise les requ√™tes cross-origin

# üîë R√©cup√©ration de la cl√© API OpenAI
api_key = ''
if not api_key:
    raise ValueError("‚ùå Aucune cl√© API d√©tect√©e !")
openai.api_key = api_key

CHROMA_DB_PATH = "chroma_db"

def determine_filter(query: str):
    """
    D√©termine, √† partir de la requ√™te utilisateur, un filtre √† appliquer sur la recherche des documents.
    - Si la requ√™te contient "date" et ("prochain" ou "suiv"), on suppose que les informations sur les prochains matchs se trouvent dans la table "match_schedule".
    - Pour les demandes de probabilit√©s de victoire (mots-cl√©s "probabil", "victoire", "match", "score" ou "buteur"), on utilise la table "match_probabilities".
    - Sinon, aucun filtre n'est appliqu√©.
    """
    query_lower = query.lower()
    if "date" in query_lower and ("prochain" in query_lower or "suiv" in query_lower):
        print("DEBUG: Filtrage sur la table 'match_schedule'")
        return {"table": "match_schedule"}
    elif ("probabil" in query_lower or "score" in query_lower or "buteur" in query_lower) and ("victoire" in query_lower or "match" in query_lower):
        print("DEBUG: Filtrage sur la table 'match_probabilities'")
        return {"table": "match_probabilities"}
    else:
        return None

def extract_team_from_query(query: str):
    """
    Extraction basique du nom d'une √©quipe depuis la requ√™te.
    Vous pouvez √©tendre cette fonction avec une liste de noms d'√©quipes connus ou un traitement NLP plus avanc√©.
    """
    teams = ["Lille", "Paris", "Marseille", "Lyon", "Monaco", "Bordeaux", "Rennes"]  # Exemple de liste d'√©quipes
    query_lower = query.lower()
    for team in teams:
        if team.lower() in query_lower:
            return team
    return None

def process_query(query: str):
    # Chargement du vector store existant
    print("Chargement du vector store...")
    try:
        vector_store = load_vector_store()
        print("‚úÖ Vector store charg√©.")
    except Exception as e:
        logger.exception("Erreur lors du chargement du vector store")
        return {"error": "Erreur lors du chargement du vector store"}
    
    # D√©termine un √©ventuel filtre bas√© sur la requ√™te
    metadata_filter = determine_filter(query)

    # Recherche dans le vector store
    try:
        if metadata_filter:
            print("DEBUG: Utilisation du filtre:", metadata_filter)
            search_results = vector_store.similarity_search(query, k=3, filter=metadata_filter)
        else:
            search_results = vector_store.similarity_search(query, k=3)
    except Exception as e:
        logger.exception("Erreur lors de la recherche dans le vector store")
        return {"error": "Erreur lors de la recherche dans le vector store"}

    query_lower = query.lower()
    # Si la requ√™te concerne les matchs √† venir (filtre "match_schedule") et mentionne "prochain",
    # tenter d'extraire le nom de l'√©quipe pour rechercher le prochain match.
    if metadata_filter and metadata_filter.get("table") == "match_schedule" and "prochain" in query_lower:
        team = extract_team_from_query(query)
        if team:
            print(f"DEBUG: √âquipe extraite de la requ√™te : {team}")
            match_doc = None
            for doc in search_results:
                if team.lower() in doc.page_content.lower():
                    match_doc = doc
                    break
            if match_doc:
                context = match_doc.page_content
            else:
                error_msg = f"Aucun match √† venir trouv√© pour l'√©quipe {team}."
                print("DEBUG:", error_msg)
                return {"error": error_msg}
        else:
            error_msg = "Aucune √©quipe d√©tect√©e dans la requ√™te pour rechercher le prochain match."
            print("DEBUG:", error_msg)
            return {"error": error_msg}
    else:
        # Concat√®ne le contenu textuel des documents trouv√©s
        context = "\n".join([doc.page_content for doc in search_results])
    
    print("DEBUG: Contexte r√©cup√©r√©:")
    print(context)
    
    # Choix du message syst√®me en fonction de la requ√™te
    if ("prochain" in query_lower or "suiv" in query_lower) and "date" in query_lower:
        system_message = (
            "Tu es un expert en paris sportifs. Lorsque tu r√©ponds √† une question sur les matchs √† venir, "
            "fournis la date exacte (jour, mois, ann√©e) et l'heure pr√©cise du prochain match, ainsi que le nom de l'adversaire si disponible. "
            "Si les donn√©es sont insuffisantes, indique clairement quelles informations manquent et donne une estimation par d√©faut."
        )
    elif metadata_filter and metadata_filter.get("table") == "match_probabilities":
        system_message = (
            "Tu es un expert en paris sportifs. Pour r√©pondre aux questions sur les probabilit√©s de victoire entre deux √©quipes, "
            "utilise uniquement les informations issues des donn√©es suivantes :\n"
            "- Probabilit√© de victoire de l'√©quipe 1 (prob_win_team1)\n"
            "- Probabilit√© de victoire de l'√©quipe 2 (prob_win_team2)\n"
            "- Score pr√©dit de l'√©quipe 1 (predicted_score_team1)\n"
            "- Score pr√©dit de l'√©quipe 2 (predicted_score_team2)\n"
            "- Meilleurs buteurs (top_scorers)\n\n"
            "Pr√©sente ces informations de mani√®re claire et structur√©e. "
            "Si certaines donn√©es sont manquantes, indique lesquelles et donne une estimation par d√©faut (par exemple, 50% pour chaque √©quipe et 0-0 pour les scores)."
        )
    else:
        system_message = (
            "Tu es un expert en paris sportifs. R√©ponds uniquement en te basant sur les donn√©es fournies ci-dessous, sans utiliser d'informations externes. "
            "Si les donn√©es sont insuffisantes, indique clairement quelles informations manquent."
        )
    
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": f"Voici les donn√©es pertinentes trouv√©es :\n{context}\n\nRequ√™te : {query}"}
    ]
    
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )
        chatbot_reply = response.choices[0].message.content
    except OpenAIError as e:
        logger.exception("Erreur OpenAI")
        chatbot_reply = f"Erreur OpenAI: {str(e)}"
    except Exception as ex:
        logger.exception("Erreur inattendue")
        chatbot_reply = f"Erreur: {str(ex)}"
    
    return {"ai_response": chatbot_reply, "context": context}

@app.route("/", methods=["GET"])
def index():
    return "IA Test API is running", 200

@app.route("/chat", methods=["POST"])
def chat():
    data = request.get_json()
    query = data.get("query")
    if not query:
        return jsonify({"error": "Missing query parameter"}), 400
    result = process_query(query)
    return jsonify(result)

if __name__ == "__main__":
    app.run(debug=True)

